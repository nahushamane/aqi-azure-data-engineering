{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8524f80d-2c80-4f76-b6b8-7496e8a96d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# access configuration settings\n",
    "storage_account_name = \"dlaqimddev\"\n",
    "client_id = dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"client-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"client-secret\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"tenant-id\")\n",
    "\n",
    "# Configure OAuth 2.0 connection\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account_name}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account_name}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account_name}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account_name}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account_name}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55de6019-14f9-48e9-a7a3-115ac6a94e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, to_timestamp, current_timestamp, expr\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5678eebe-5eb1-4b8a-8b65-1e611cd6a746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Read Raw JSON from Bronze (Wildcard path for daily folders)\n",
    "bronze_path = f\"abfss://bronze@{storage_account_name}.dfs.core.windows.net/cpcb_aqi/*/*/*/*.json\"\n",
    "df_bronze = spark.read.option(\"multiline\", \"true\").json(bronze_path)\n",
    "\n",
    "# 2. Explode the 'records' array to flatten the data\n",
    "df_records = df_bronze.select(explode(col(\"records\")).alias(\"rec\")).select(\"rec.*\")\n",
    "\n",
    "df_records.show()\n",
    "df_records.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fecb3e0-6d84-4277-837c-1ba3267fe813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Clean, Cast, and Filter\n",
    "df_silver = df_records \\\n",
    "    .withColumn(\"last_update\", to_timestamp(col(\"last_update\"), \"dd-MM-yyyy HH:mm:ss\")) \\\n",
    "    .withColumn(\"avg_value\", expr(\"try_cast(avg_value as int)\")) \\\n",
    "    .withColumn(\"max_value\", expr(\"try_cast(max_value as int)\")) \\\n",
    "    .withColumn(\"min_value\", expr(\"try_cast(min_value as int)\")) \\\n",
    "    .withColumn(\"latitude\", expr(\"try_cast(latitude as double)\")) \\\n",
    "    .withColumn(\"longitude\", expr(\"try_cast(longitude as double)\")) \\\n",
    "    .filter(col(\"avg_value\").isNotNull()) \\\n",
    "    .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "\n",
    "df_silver.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b5a3f6-867c-477b-a31a-050c590ac435",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Save to Silver\n",
    "silver_path = f\"abfss://silver@{storage_account_name}.dfs.core.windows.net/cpcb_aqi/\"\n",
    "\n",
    "# 4.1 Deduplicate the incoming batch first\n",
    "# We use station, pollutant_id, and last_update as the unique key for Silver\n",
    "df_silver_unique = df_silver.dropDuplicates([\"station\", \"pollutant_id\", \"last_update\"])\n",
    "\n",
    "display(df_silver_unique.limit(10))\n",
    "\n",
    "# 4.2 Check if Silver Delta table exists\n",
    "if DeltaTable.isDeltaTable(spark, silver_path):\n",
    "    silver_table = DeltaTable.forPath(spark, silver_path)\n",
    "    \n",
    "    # 4.3 Perform the Merge (Upsert)\n",
    "    silver_table.alias(\"target\").merge(\n",
    "        df_silver_unique.alias(\"source\"),\n",
    "        \"target.station = source.station AND \\\n",
    "         target.pollutant_id = source.pollutant_id AND \\\n",
    "         target.last_update = source.last_update\"\n",
    "    ).whenMatchedUpdateAll() \\\n",
    "     .whenNotMatchedInsertAll() \\\n",
    "     .execute()\n",
    "    print(\"Bronze data successfully merged into Silver layer.\")\n",
    "else:\n",
    "    # 4.4 Create table for the first time\n",
    "    df_silver_unique.write.format(\"delta\").mode(\"overwrite\").save(silver_path)\n",
    "    print(\"Silver table created and initial data loaded.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1_bronze_to_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
