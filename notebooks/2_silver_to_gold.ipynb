{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22b87d44-1a9e-4892-9730-1a0b61d2bcae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# access configuration settings\n",
    "storage_account_name = \"dlaqimddev\"\n",
    "client_id = dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"client-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"client-secret\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"key-vault-secrets\", key=\"tenant-id\")\n",
    "\n",
    "# Configure OAuth 2.0 connection\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account_name}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account_name}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account_name}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account_name}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account_name}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aed5e2a2-5aab-4659-b3ff-fa53b2c7fcce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, col\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5806de0-23e1-43cf-9c0a-da38b94740f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# source and target paths\n",
    "silver_path = f\"abfss://silver@{storage_account_name}.dfs.core.windows.net/cpcb_aqi\"\n",
    "gold_path = f\"abfss://gold@{storage_account_name}.dfs.core.windows.net/cpcb_aqi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16189458-4b7f-4a83-aa08-afb7f1dd81de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. load the cleaned silver data\n",
    "df_silver = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "display(df_silver.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d896c180-3c2b-4467-bcba-650064a1655a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. DIMENSION: location\n",
    "# extract unique geographic attributes\n",
    "dim_location = df_silver.select(\"country\", \"state\", \"city\", \"station\", \"longitude\", \"latitude\").distinct().withColumn(\"location_key\", monotonically_increasing_id())\n",
    "\n",
    "display(dim_location.limit(10))\n",
    "\n",
    "# location\n",
    "dim_location.write.format(\"delta\").mode(\"overwrite\").save(gold_path + \"dim_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc60b36-85a0-4a6e-a464-220b6fafd757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. DIMENSION: pollutant\n",
    "# extract unique pollutant ids\n",
    "dim_pollutant = df_silver.select(\"pollutant_id\").distinct().withColumn(\"pollutant_key\", monotonically_increasing_id())\n",
    "\n",
    "display(dim_pollutant.limit(10))\n",
    "\n",
    "# pollutant\n",
    "dim_pollutant.write.format(\"delta\").mode(\"overwrite\").save(gold_path + \"dim_pollutant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "054a6c4c-b4c0-4e70-9c46-18ad4d14ff2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. FACT: aqi measurement\n",
    "# join back to dimensions to replace strings with surrogate keys\n",
    "fact_aqi = df_silver.join(dim_location, [\"country\", \"state\", \"city\", \"station\", \"longitude\", \"latitude\"], how=\"left\").join(dim_pollutant, [\"pollutant_id\"],how=\"left\").select(\n",
    "    col(\"location_key\"),\n",
    "    col(\"pollutant_key\"),\n",
    "    col(\"last_update\").alias(\"measurement_time\"),\n",
    "    col(\"avg_value\").alias(\"aqi_avg\"),\n",
    "    col(\"max_value\").alias(\"aqi_max\"),\n",
    "    col(\"min_value\").alias(\"aqi_min\")\n",
    ")\n",
    "\n",
    "display(fact_aqi.limit(10))\n",
    "\n",
    "## 1. Load the new data you just processed (Incremental batch)\n",
    "new_fact_data = fact_aqi\n",
    "\n",
    "## 2. Check if the Gold table already exists\n",
    "if DeltaTable.isDeltaTable(spark, gold_path + \"fact_aqi\"):\n",
    "    gold_fact_table = DeltaTable.forPath(spark, gold_path + \"fact_aqi\")\n",
    "    \n",
    "    # 3. Perform the Merge (Upsert)\n",
    "    gold_fact_table.alias(\"old\").merge(\n",
    "        new_fact_data.alias(\"new\"),\n",
    "        # Define the unique key: Same Location, Same Pollutant, Same Time\n",
    "        \"old.location_key = new.location_key AND old.pollutant_key = new.pollutant_key AND old.measurement_time = new.measurement_time\"\n",
    "    ).whenMatchedUpdateAll() \\\n",
    "     .whenNotMatchedInsertAll() \\\n",
    "     .execute()\n",
    "    print(\"New data successfully merged into Gold table\")\n",
    "else:\n",
    "    # 4. If table doesn't exist, create it for the first time\n",
    "    new_fact_data.write.format(\"delta\").mode(\"overwrite\").save(gold_path + \"fact_aqi\")\n",
    "    print(\"New data successfully written to Gold table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f45ddeae-252f-4775-8f15-0ca4b1ec7f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Total no. of rows read from silver: {df_silver.count()}\")\n",
    "print(f\"Total no. of rows extracted for dim_location: {dim_location.count()}\")\n",
    "print(f\"Total no. of rows extracted for dim_pollutant: {dim_pollutant.count()}\")\n",
    "print(f\"Total no. of rows extracted for fact_aqi: {fact_aqi.count()}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_silver_to_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
